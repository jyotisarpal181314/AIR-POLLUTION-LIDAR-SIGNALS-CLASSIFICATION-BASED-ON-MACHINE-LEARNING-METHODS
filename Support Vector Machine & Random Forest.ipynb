{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measurements of Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p                #importing the necessary modules and libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as s\n",
    "import numpy as n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=p.read_excel(\"Data1.xlsx\")   #classified data according to cities and average, max and min values of NO2 in them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Avg1</th>\n",
       "      <th>Max1</th>\n",
       "      <th>Min1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>0</td>\n",
       "      <td>42.08</td>\n",
       "      <td>39.00</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aizwal</td>\n",
       "      <td>0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>5.20</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>0</td>\n",
       "      <td>10.36</td>\n",
       "      <td>16.70</td>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amritsar</td>\n",
       "      <td>0</td>\n",
       "      <td>51.27</td>\n",
       "      <td>28.02</td>\n",
       "      <td>7.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0</td>\n",
       "      <td>31.04</td>\n",
       "      <td>19.65</td>\n",
       "      <td>9.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City  Last Update   Avg1   Max1  Min1\n",
       "0  Ahmedabad            0  42.08  39.00  7.80\n",
       "1     Aizwal            0   4.10   5.20  3.10\n",
       "2  Amaravati            0  10.36  16.70  6.53\n",
       "3   Amritsar            0  51.27  28.02  7.79\n",
       "4  Bengaluru            0  31.04  19.65  9.72"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column according to the data.\n",
    "AQI=['Satisfactory','Good' , 'Good','Satisfactory','Good', 'Good', 'Good','Satisfactory','Satisfactory', 'Good', 'Moderate', 'Good', 'Good','Good','Satisfactory','Good', 'Good', 'Moderate','Good','Satisfactory','Good','Good','Satisfactory','Good','Moderate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AQI']=AQI #added to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding class to the dataset which is derieved on the values according to AQI\n",
    "df['class'] = df.AQI.map({'Good':2, 'Satisfactory':1,'Moderate':0}) #class defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Avg1</th>\n",
       "      <th>Max1</th>\n",
       "      <th>Min1</th>\n",
       "      <th>AQI</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>0</td>\n",
       "      <td>42.08</td>\n",
       "      <td>39.00</td>\n",
       "      <td>7.80</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aizwal</td>\n",
       "      <td>0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>5.20</td>\n",
       "      <td>3.10</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>0</td>\n",
       "      <td>10.36</td>\n",
       "      <td>16.70</td>\n",
       "      <td>6.53</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amritsar</td>\n",
       "      <td>0</td>\n",
       "      <td>51.27</td>\n",
       "      <td>28.02</td>\n",
       "      <td>7.79</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0</td>\n",
       "      <td>31.04</td>\n",
       "      <td>19.65</td>\n",
       "      <td>9.72</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City  Last Update   Avg1   Max1  Min1           AQI  class\n",
       "0  Ahmedabad            0  42.08  39.00  7.80  Satisfactory      1\n",
       "1     Aizwal            0   4.10   5.20  3.10          Good      2\n",
       "2  Amaravati            0  10.36  16.70  6.53          Good      2\n",
       "3   Amritsar            0  51.27  28.02  7.79  Satisfactory      1\n",
       "4  Bengaluru            0  31.04  19.65  9.72          Good      2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['AQI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['City','Last Update','Avg1','Max1','Min1','class']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(labels='class',axis=1)\n",
    "y=df.loc[:,'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #spliting our data to training sets and test sets\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y, test_size=0.2, random_state=1,stratify=y)\n",
    "#  test_size :Ratio by which we are splitting\n",
    "#70% model used for training and rest 30% used for testing for predicting actual accuracy.\n",
    "#  Random state used for keeking values constant means we dont want to change them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Classification report of Support Vector Machines Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.62      1.00      0.77         5\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.21      0.33      0.26         8\n",
      "weighted avg       0.39      0.62      0.48         8\n",
      "\n",
      "Cross validation test results of accuracy:\n",
      "[1.         0.5        0.5        0.5        0.66666667 0.66666667\n",
      " 0.66666667]\n",
      "\n",
      "Accuracy result of Support Vector Machines is: 64.28571428571429\n",
      "\n",
      "Confusion Matrix result of Support Vector Machines is:\n",
      " [[0 0 1]\n",
      " [0 0 2]\n",
      " [0 0 5]]\n",
      "\n",
      "Senstivity : nan\n",
      "\n",
      "specificity : nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "s = SVC()\n",
    "\n",
    "s.fit(X_train,y_train)\n",
    "predicts = s.predict(X_test)\n",
    "print(\" \")\n",
    "print(\"Classification report of Support Vector Machines Report:\")\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predicts)) # shows classification metrics precision, recall and f1 score\n",
    "\n",
    "# Accuracy is the correctly classified data instances over the total number of data instances.\n",
    "# Cross validation is to evaluate our models\n",
    "accuracy = cross_val_score(s ,X, y, cv=7) #splitting the data according to cv dividing it into training and testing\n",
    "print(\"Cross validation test results of accuracy:\")\n",
    "print(accuracy)\n",
    "print(\"\")\n",
    "# get mean of every field\n",
    "print(\"Accuracy result of Support Vector Machines is:\",accuracy.mean()*100)\n",
    "print(\"\")\n",
    "\n",
    "cm1=confusion_matrix(y_test,predicts) #evaluating the performance of a classification model\n",
    "print(\"Confusion Matrix result of Support Vector Machines is:\\n\",cm1)\n",
    "print(\"\")\n",
    "sensitivity1= cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print(\"Senstivity :\",sensitivity1) #  Cases actual positive cases that got predicted as true\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print(\"specificity :\",specificity1)  #  Cases actual positive cases that got predicted as false\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive : 0\n",
      "True negative : 0\n",
      "False positive : 0\n",
      "False negative : 0\n",
      "\n",
      "\n",
      "True positive Rate : nan\n",
      "True negative Rate : nan\n",
      "False positive Rate: nan\n",
      "False negative Rate : nan\n"
     ]
    }
   ],
   "source": [
    "TN = cm1[0][0]\n",
    "FN = cm1[1][0]\n",
    "TP = cm1[1][1]\n",
    "FP = cm1[0][1]\n",
    "print(\"True positive :\",TP)\n",
    "print(\"True negative :\",TN)\n",
    "print(\"False positive :\",FP)\n",
    "print(\"False negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"\")\n",
    "print(\"True positive Rate :\",TPR)\n",
    "print(\"True negative Rate :\",TNR)\n",
    "print(\"False positive Rate:\",FPR)\n",
    "print(\"False negative Rate :\",FNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measurements of Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Classification report of Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.40         5\n",
      "   macro avg       0.22      0.22      0.22         5\n",
      "weighted avg       0.40      0.40      0.40         5\n",
      "\n",
      "Cross validation test results of accuracy:\n",
      "[0.5        0.5        0.5        0.75       0.66666667 0.66666667\n",
      " 1.        ]\n",
      "\n",
      "Accuracy result of Random Forest is: 65.47619047619048\n",
      "\n",
      "Confusion Matrix result of Random Forests is:\n",
      " [[0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 2]]\n",
      "\n",
      "Senstivity : 0.0\n",
      "\n",
      "specificity : nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "# random forest model creation\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "predicts = rfc.predict(X_test)\n",
    "print(\" \")\n",
    "print(\"Classification report of Random Forest:\")\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predicts)) # shows classification metrics precision, recall and f1 score\n",
    "\n",
    "# Accuracy is the correctly classified data instances over the total number of data instances.\n",
    "# Cross validation is to evaluate our models\n",
    "accuracy = cross_val_score(rfc ,X, y, cv=7) #splitting the data according to cv dividing it into training and testing\n",
    "print(\"Cross validation test results of accuracy:\")\n",
    "print(accuracy)\n",
    "print(\"\")\n",
    "# get mean of every field\n",
    "print(\"Accuracy result of Random Forest is:\",accuracy.mean()*100)\n",
    "print(\"\")\n",
    "\n",
    "cm1=confusion_matrix(y_test,predicts) #evaluating the performance of a classification model\n",
    "print(\"Confusion Matrix result of Random Forests is:\\n\",cm1)\n",
    "print(\"\")\n",
    "sensitivity1= cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print(\"Senstivity :\",sensitivity1) #  Cases actual positive cases that got predicted as true\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print(\"specificity :\",specificity1)  #  Cases actual positive cases that got predicted as false\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive : 0\n",
      "True negative : 0\n",
      "False positive : 1\n",
      "False negative : 0\n",
      "\n",
      "\n",
      "True positive Rate : nan\n",
      "True negative Rate : 0.0\n",
      "False positive Rate: 1.0\n",
      "False negative Rate : nan\n"
     ]
    }
   ],
   "source": [
    "TN = cm1[0][0]\n",
    "FN = cm1[1][0]\n",
    "TP = cm1[1][1]\n",
    "FP = cm1[0][1]\n",
    "print(\"True positive :\",TP)\n",
    "print(\"True negative :\",TN)\n",
    "print(\"False positive :\",FP)\n",
    "print(\"False negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"\")\n",
    "print(\"True positive Rate :\",TPR)\n",
    "print(\"True negative Rate :\",TNR)\n",
    "print(\"False positive Rate:\",FPR)\n",
    "print(\"False negative Rate :\",FNR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
